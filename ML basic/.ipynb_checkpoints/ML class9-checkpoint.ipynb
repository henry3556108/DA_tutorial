{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347552ca",
   "metadata": {},
   "source": [
    "### 類別特徵處理\n",
    "\n",
    "類別特徵是不能用數值表示的特徵，例如性別、顏色、國家等。類別特徵處理的常用技術包括：\n",
    "\n",
    "標籤編碼：將類別特徵轉換為數值。\n",
    "\n",
    "讀熱編碼：將類別特徵轉換為二進制向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1dfd613b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  SexLabel  \n",
      "0      0         A/5 21171   7.2500   NaN        S         1  \n",
      "1      0          PC 17599  71.2833   C85        C         0  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S         0  \n",
      "3      0            113803  53.1000  C123        S         0  \n",
      "4      0            373450   8.0500   NaN        S         1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 讀取數據\n",
    "df = pd.read_csv(\"dataset/titanic/train.csv\")\n",
    "\n",
    "# 選擇類別特徵\n",
    "categorical_features = \"Sex\"\n",
    "\n",
    "# 標籤編碼\n",
    "le = LabelEncoder()\n",
    "df[\"SexLabel\"] = le.fit_transform(df[\"Sex\"])\n",
    "\n",
    "# 查看結果\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38e6650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex_female' 'Sex_male' 'Embarked_C' 'Embarked_Q' 'Embarked_S'\n",
      " 'Embarked_nan']\n",
      "[[0. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 讀取數據\n",
    "df = pd.read_csv(\"dataset/titanic.csv\")\n",
    "\n",
    "# 選擇類別特徵\n",
    "categorical_features = [\"Sex\", \"Embarked\"]\n",
    "# df[\"Embarked\"].unique()\n",
    "# 讀熱編碼\n",
    "ohe = OneHotEncoder()\n",
    "df_encoded = ohe.fit_transform(df[categorical_features])\n",
    "\n",
    "# 查看結果\n",
    "print(ohe.get_feature_names_out())\n",
    "print(df_encoded.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726b323",
   "metadata": {},
   "source": [
    "## 文本編碼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3815de",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "CountVectorizer 是將文本轉換為詞頻矩陣的一種方法。這個詞頻矩陣中，每一行代表一個文檔，每一列代表一個詞語，矩陣中的值代表每個詞語在每個文檔中出現的次數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0166aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   and  coding  exciting  fun  is  learning  love  machine\n",
      "0    0       0         0    0   0         1     1        1\n",
      "1    0       0         0    1   1         1     0        1\n",
      "2    0       1         0    0   0         0     1        0\n",
      "3    1       1         1    1   1         0     0        0\n",
      "4    1       1         0    0   0         1     1        1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 文本資料\n",
    "texts = [\n",
    "    'I love machine learning',\n",
    "    'Machine learning is fun',\n",
    "    'I love coding',\n",
    "    'Coding is fun and exciting',\n",
    "    'I love coding but hate machine learning'\n",
    "]\n",
    "\n",
    "# 創建 CountVectorizer 物件\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# 將文本資料轉換為詞頻矩陣\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# 獲取詞語特徵\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 將結果轉換為DataFrame以便查看\n",
    "df = pd.DataFrame(X.toarray(), columns=features)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd8439",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "TF-IDF 用於文本資料，計算詞頻和逆文檔頻率的乘積，表示詞在文檔中的重要性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58823658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      text\n",
      "0  I love machine learning\n",
      "1  Machine learning is fun\n",
      "2            I love coding\n",
      "          0         1         2         3         4         5\n",
      "0  0.000000  0.000000  0.000000  0.577350  0.577350  0.577350\n",
      "1  0.000000  0.562829  0.562829  0.428046  0.000000  0.428046\n",
      "2  0.795961  0.000000  0.000000  0.000000  0.605349  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# 假設我們有一個包含文本資料的資料框\n",
    "df_text = pd.DataFrame({'text': ['I love machine learning', 'Machine learning is fun', 'I love coding']})\n",
    "\n",
    "\n",
    "print(df_text)\n",
    "# 使用TfidfVectorizer進行編碼\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df_text['text'])\n",
    "\n",
    "print(pd.DataFrame(tfidf_matrix.toarray()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4e7be",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "Word Embeddings (如Word2Vec, GloVe) 將詞語轉換為稠密向量，這些向量可以捕捉詞語之間的語義關係。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d953a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00855287  0.00015212 -0.01916856 -0.01933109 -0.01229639 -0.00025714\n",
      "  0.00399483  0.01886394  0.0111687  -0.00858139  0.00055663  0.00992872\n",
      "  0.01539662 -0.00228845  0.00864684 -0.01162876 -0.00160838  0.0162001\n",
      " -0.00472013 -0.01932691  0.01155852 -0.00785964 -0.00244575  0.01996103\n",
      " -0.0045127  -0.00951413 -0.01065877  0.01396178 -0.01141774  0.00422733\n",
      " -0.01051132  0.01224143  0.00871461  0.00521271 -0.00298217 -0.00549213\n",
      "  0.01798587  0.01043155 -0.00432504 -0.01894062 -0.0148521  -0.00212748\n",
      " -0.00158989 -0.00512582  0.01936544 -0.00091704  0.01174752 -0.01489517\n",
      " -0.00501215 -0.01109973]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 假設我們有一個包含文本資料的列表\n",
    "sentences = [['I', 'love', 'machine', 'learning'], ['Machine', 'learning', 'is', 'fun'], ['I', 'love', 'coding']]\n",
    "\n",
    "# 訓練Word2Vec模型\n",
    "model = Word2Vec(sentences, vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# 獲取單詞向量\n",
    "word_vector = model.wv['machine']\n",
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088abe91",
   "metadata": {},
   "source": [
    "## 練習\n",
    "嘗試使用 CountVectorizer 來萃取以下的 texts 內文字的特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae6fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'The quick brown fox jumps over the lazy dog',\n",
    "    'Never jump over the lazy dog quickly',\n",
    "    'Bright sun and warm weather make a perfect day',\n",
    "    'The weather is bright and sunny today',\n",
    "    'Dogs are loyal and friendly animals',\n",
    "    'Foxes are quick and cunning creatures'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20103450",
   "metadata": {},
   "source": [
    "## 回家作業\n",
    "- 練習使用三種不同的方法來去處理電影的大綱，依此來預測一個電影的評分。\n",
    "- 根據預測的結果做一個簡單的結論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710139e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
