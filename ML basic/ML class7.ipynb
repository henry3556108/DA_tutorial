{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57c11ce",
   "metadata": {},
   "source": [
    "## 異常值處理方法\n",
    "\n",
    "**刪除異常值**\n",
    "\n",
    "刪除異常值是最簡單的處理異常值的方法。但是，這種方法可能會導致資料量的減少，從而影響資料分析結果的準確性。\n",
    "\n",
    "**將異常值替換為平均值或中位數**\n",
    "\n",
    "這種方法是使用統計方法來估算異常值。平均值是將所有非異常值的平均值用於替換異常值。中位數是將所有非異常值的眾數用於替換異常值。\n",
    "\n",
    "## 缺失值的處理方法\n",
    "\n",
    "**刪除包含缺失值的樣本**\n",
    "\n",
    "刪除包含缺失值的樣本是最簡單的處理缺失值的方法。但是，這種方法可能會導致資料量的減少，從而影響資料分析結果的準確性。\n",
    "\n",
    "**使用平均值、中位數或眾數填充缺失值**\n",
    "\n",
    "這種方法是使用統計方法來估算缺失值。平均值是使用所有非缺失值的平均值來填充缺失值。中位數是使用所有非缺失值的眾數來填充缺失值。眾數是使用所有非缺失值出現最多的值來填充缺失值。\n",
    "\n",
    "**使用插補方法填充缺失值**\n",
    "\n",
    "插補方法是使用相鄰資料點的值來估算缺失值。常用的插補方法包括線性插補、拋物線插補和三次曲線插補。\n",
    "通常在時間序列的資料中會使用到\n",
    "\n",
    "**使用機器學習方法填充缺失值**\n",
    "\n",
    "機器學習方法可以自動估算缺失值。常用的機器學習方法包括 KNN 等等模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe31e58b",
   "metadata": {},
   "source": [
    "## 插值法\n",
    "\n",
    "- [官方連結](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html)\n",
    "\n",
    "```\n",
    "DataFrame.interpolate(method='linear', axis=0, limit=None, fill_value=None, inplace=False, **kwargs)\n",
    "```\n",
    "- method：插補方法。默認為 linear，即線性插補。其他可選值包括：\n",
    "  - nearest：最近鄰居插補\n",
    "  - zero：用 0 填充缺失值\n",
    "  - slinear：線性插補，但只使用相鄰的非缺失值\n",
    "  - quadratic：拋物線插補\n",
    "  - cubic：三次曲線插補\n",
    "  - polynomial：多項式插補\n",
    "  - spline：樣條插補\n",
    "  - piecewise_polynomial：分段多項式插補\n",
    "  - from_derivatives：從導數插補\n",
    "  - pchip：PCHIP 插補\n",
    "  - akima：Akima 插補\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fafab87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date   Open  High  Low  Close  Volume\n",
      "0 2023-01-01  100.0   105   95    100   10000\n",
      "1 2023-01-02  101.0   106   96    101   10100\n",
      "2 2023-01-03  102.0   107   97    102   10200\n",
      "3 2023-01-04  103.0   108   98    103   10300\n",
      "4 2023-01-05  104.0   109   99    104   10400\n",
      "5 2023-01-06    NaN   110  100    105   10500\n",
      "6 2023-01-07  106.0   111  101    106   10600\n",
      "7 2023-01-08  107.0   112  102    107   10700\n",
      "8 2023-01-09    NaN   113  103    108   10800\n",
      "9 2023-01-10  109.0   114  104    109   10900\n",
      "             Open  High  Low  Close  Volume\n",
      "Date                                       \n",
      "2023-01-01  100.0   105   95    100   10000\n",
      "2023-01-02  101.0   106   96    101   10100\n",
      "2023-01-03  102.0   107   97    102   10200\n",
      "2023-01-04  103.0   108   98    103   10300\n",
      "2023-01-05  104.0   109   99    104   10400\n",
      "2023-01-06  105.0   110  100    105   10500\n",
      "2023-01-07  106.0   111  101    106   10600\n",
      "2023-01-08  107.0   112  102    107   10700\n",
      "2023-01-09  108.0   113  103    108   10800\n",
      "2023-01-10  109.0   114  104    109   10900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 讀取資料\n",
    "data = pd.read_csv('dataset/time_series_data.csv')\n",
    "\n",
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "print(data)\n",
    "data = data.set_index(\"Date\")\n",
    "# 填充缺失值\n",
    "inter_data = data.interpolate()\n",
    "print(inter_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e43b56",
   "metadata": {},
   "source": [
    "## 平均值的優缺點\n",
    "\n",
    "### 優點：\n",
    "\n",
    "- 計算簡單\n",
    "- 可以保留數據的原始信息\n",
    "\n",
    "### 缺點：\n",
    "\n",
    "- 容易受到異常值的影響\n",
    "- 不適用於非正態分布的數據\n",
    "\n",
    "## 眾數的優缺點\n",
    "\n",
    "### 優點：\n",
    "\n",
    "- 不受異常值的影響\n",
    "- 適用於非正態分布的數據\n",
    "\n",
    "### 缺點：\n",
    "\n",
    "- 可能會降低數據的準確性\n",
    "- 不適用於數值型特徵\n",
    "\n",
    "### 重點整理\n",
    "- 對於正態分布的數據，可以使用平均值填充缺失值。\n",
    "- 對於非正態分布的數據，可以使用眾數填充缺失值。\n",
    "- 對於數值型特徵，可以使用平均值填充缺失值。\n",
    "- 對於類別型特徵，可以使用眾數填充缺失值。\n",
    "\n",
    "此外，還可以使用一些更複雜的填充方法，例如插補法和機器學習。這些方法可以更好地保留數據的原始信息，但計算量也更大。\n",
    "\n",
    "在實際應用中，可以根據具體情況選擇合適的缺失值填充方式。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56867fa2",
   "metadata": {},
   "source": [
    "- 在資料分析和機器學習中，標準化（standardization）是將資料轉換為具有零均值和單位變異數的標準正態分佈，以確保每個特徵對模型的重要性均衡。以下是一個有標準化與沒標準化對於資料分析影響的實例：\n",
    "\n",
    "### 資料集說明\n",
    "假設我們有一個包含三個特徵（特徵A、特徵B、特徵C）的資料集，用於預測某個目標變數（Target）。特徵A的數值範圍是0到1，特徵B的數值範圍是0到1000，特徵C的數值範圍是0到10。\n",
    "\n",
    "- 沒有標準化的影響\n",
    "\n",
    "當我們在沒有標準化的情況下使用這個資料集進行分析或訓練模型，特徵B的數值範圍比其他特徵大得多，這會導致以下問題：\n",
    "\n",
    "- 特徵的重要性失衡：模型可能會偏重於特徵B，因為它的數值範圍較大，導致模型對特徵A和特徵C的忽略。\n",
    "\n",
    "距離計算失真：在使用基於距離的模型（如KNN、K-means）時，特徵B的影響將遠遠大於其他特徵，導致模型性能下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14f32a",
   "metadata": {},
   "source": [
    "## 資料的格式統一\n",
    "\n",
    "### 標準化的適用情境\n",
    "\n",
    "標準化適用於以下情境：\n",
    "\n",
    "1. 資料服從正態分布\n",
    "2. 需要計算資料之間的距離\n",
    "\n",
    "### 歸一化的適用情境\n",
    "\n",
    "歸一化適用於以下情境：\n",
    "\n",
    "1. 資料不服從正態分布\n",
    "2. 資料的範圍不確定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf1b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 讀取資料\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "\n",
    "# 輸出結果\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "266698ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22222222 0.625      0.06779661 0.04166667]\n",
      " [0.16666667 0.41666667 0.06779661 0.04166667]\n",
      " [0.11111111 0.5        0.05084746 0.04166667]\n",
      " [0.08333333 0.45833333 0.08474576 0.04166667]\n",
      " [0.19444444 0.66666667 0.06779661 0.04166667]\n",
      " [0.30555556 0.79166667 0.11864407 0.125     ]\n",
      " [0.08333333 0.58333333 0.06779661 0.08333333]\n",
      " [0.19444444 0.58333333 0.08474576 0.04166667]\n",
      " [0.02777778 0.375      0.06779661 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.        ]\n",
      " [0.30555556 0.70833333 0.08474576 0.04166667]\n",
      " [0.13888889 0.58333333 0.10169492 0.04166667]\n",
      " [0.13888889 0.41666667 0.06779661 0.        ]\n",
      " [0.         0.41666667 0.01694915 0.        ]\n",
      " [0.41666667 0.83333333 0.03389831 0.04166667]\n",
      " [0.38888889 1.         0.08474576 0.125     ]\n",
      " [0.30555556 0.79166667 0.05084746 0.125     ]\n",
      " [0.22222222 0.625      0.06779661 0.08333333]\n",
      " [0.38888889 0.75       0.11864407 0.08333333]\n",
      " [0.22222222 0.75       0.08474576 0.08333333]\n",
      " [0.30555556 0.58333333 0.11864407 0.04166667]\n",
      " [0.22222222 0.70833333 0.08474576 0.125     ]\n",
      " [0.08333333 0.66666667 0.         0.04166667]\n",
      " [0.22222222 0.54166667 0.11864407 0.16666667]\n",
      " [0.13888889 0.58333333 0.15254237 0.04166667]\n",
      " [0.19444444 0.41666667 0.10169492 0.04166667]\n",
      " [0.19444444 0.58333333 0.10169492 0.125     ]\n",
      " [0.25       0.625      0.08474576 0.04166667]\n",
      " [0.25       0.58333333 0.06779661 0.04166667]\n",
      " [0.11111111 0.5        0.10169492 0.04166667]\n",
      " [0.13888889 0.45833333 0.10169492 0.04166667]\n",
      " [0.30555556 0.58333333 0.08474576 0.125     ]\n",
      " [0.25       0.875      0.08474576 0.        ]\n",
      " [0.33333333 0.91666667 0.06779661 0.04166667]\n",
      " [0.16666667 0.45833333 0.08474576 0.04166667]\n",
      " [0.19444444 0.5        0.03389831 0.04166667]\n",
      " [0.33333333 0.625      0.05084746 0.04166667]\n",
      " [0.16666667 0.66666667 0.06779661 0.        ]\n",
      " [0.02777778 0.41666667 0.05084746 0.04166667]\n",
      " [0.22222222 0.58333333 0.08474576 0.04166667]\n",
      " [0.19444444 0.625      0.05084746 0.08333333]\n",
      " [0.05555556 0.125      0.05084746 0.08333333]\n",
      " [0.02777778 0.5        0.05084746 0.04166667]\n",
      " [0.19444444 0.625      0.10169492 0.20833333]\n",
      " [0.22222222 0.75       0.15254237 0.125     ]\n",
      " [0.13888889 0.41666667 0.06779661 0.08333333]\n",
      " [0.22222222 0.75       0.10169492 0.04166667]\n",
      " [0.08333333 0.5        0.06779661 0.04166667]\n",
      " [0.27777778 0.70833333 0.08474576 0.04166667]\n",
      " [0.19444444 0.54166667 0.06779661 0.04166667]\n",
      " [0.75       0.5        0.62711864 0.54166667]\n",
      " [0.58333333 0.5        0.59322034 0.58333333]\n",
      " [0.72222222 0.45833333 0.66101695 0.58333333]\n",
      " [0.33333333 0.125      0.50847458 0.5       ]\n",
      " [0.61111111 0.33333333 0.61016949 0.58333333]\n",
      " [0.38888889 0.33333333 0.59322034 0.5       ]\n",
      " [0.55555556 0.54166667 0.62711864 0.625     ]\n",
      " [0.16666667 0.16666667 0.38983051 0.375     ]\n",
      " [0.63888889 0.375      0.61016949 0.5       ]\n",
      " [0.25       0.29166667 0.49152542 0.54166667]\n",
      " [0.19444444 0.         0.42372881 0.375     ]\n",
      " [0.44444444 0.41666667 0.54237288 0.58333333]\n",
      " [0.47222222 0.08333333 0.50847458 0.375     ]\n",
      " [0.5        0.375      0.62711864 0.54166667]\n",
      " [0.36111111 0.375      0.44067797 0.5       ]\n",
      " [0.66666667 0.45833333 0.57627119 0.54166667]\n",
      " [0.36111111 0.41666667 0.59322034 0.58333333]\n",
      " [0.41666667 0.29166667 0.52542373 0.375     ]\n",
      " [0.52777778 0.08333333 0.59322034 0.58333333]\n",
      " [0.36111111 0.20833333 0.49152542 0.41666667]\n",
      " [0.44444444 0.5        0.6440678  0.70833333]\n",
      " [0.5        0.33333333 0.50847458 0.5       ]\n",
      " [0.55555556 0.20833333 0.66101695 0.58333333]\n",
      " [0.5        0.33333333 0.62711864 0.45833333]\n",
      " [0.58333333 0.375      0.55932203 0.5       ]\n",
      " [0.63888889 0.41666667 0.57627119 0.54166667]\n",
      " [0.69444444 0.33333333 0.6440678  0.54166667]\n",
      " [0.66666667 0.41666667 0.6779661  0.66666667]\n",
      " [0.47222222 0.375      0.59322034 0.58333333]\n",
      " [0.38888889 0.25       0.42372881 0.375     ]\n",
      " [0.33333333 0.16666667 0.47457627 0.41666667]\n",
      " [0.33333333 0.16666667 0.45762712 0.375     ]\n",
      " [0.41666667 0.29166667 0.49152542 0.45833333]\n",
      " [0.47222222 0.29166667 0.69491525 0.625     ]\n",
      " [0.30555556 0.41666667 0.59322034 0.58333333]\n",
      " [0.47222222 0.58333333 0.59322034 0.625     ]\n",
      " [0.66666667 0.45833333 0.62711864 0.58333333]\n",
      " [0.55555556 0.125      0.57627119 0.5       ]\n",
      " [0.36111111 0.41666667 0.52542373 0.5       ]\n",
      " [0.33333333 0.20833333 0.50847458 0.5       ]\n",
      " [0.33333333 0.25       0.57627119 0.45833333]\n",
      " [0.5        0.41666667 0.61016949 0.54166667]\n",
      " [0.41666667 0.25       0.50847458 0.45833333]\n",
      " [0.19444444 0.125      0.38983051 0.375     ]\n",
      " [0.36111111 0.29166667 0.54237288 0.5       ]\n",
      " [0.38888889 0.41666667 0.54237288 0.45833333]\n",
      " [0.38888889 0.375      0.54237288 0.5       ]\n",
      " [0.52777778 0.375      0.55932203 0.5       ]\n",
      " [0.22222222 0.20833333 0.33898305 0.41666667]\n",
      " [0.38888889 0.33333333 0.52542373 0.5       ]\n",
      " [0.55555556 0.54166667 0.84745763 1.        ]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.77777778 0.41666667 0.83050847 0.83333333]\n",
      " [0.55555556 0.375      0.77966102 0.70833333]\n",
      " [0.61111111 0.41666667 0.81355932 0.875     ]\n",
      " [0.91666667 0.41666667 0.94915254 0.83333333]\n",
      " [0.16666667 0.20833333 0.59322034 0.66666667]\n",
      " [0.83333333 0.375      0.89830508 0.70833333]\n",
      " [0.66666667 0.20833333 0.81355932 0.70833333]\n",
      " [0.80555556 0.66666667 0.86440678 1.        ]\n",
      " [0.61111111 0.5        0.69491525 0.79166667]\n",
      " [0.58333333 0.29166667 0.72881356 0.75      ]\n",
      " [0.69444444 0.41666667 0.76271186 0.83333333]\n",
      " [0.38888889 0.20833333 0.6779661  0.79166667]\n",
      " [0.41666667 0.33333333 0.69491525 0.95833333]\n",
      " [0.58333333 0.5        0.72881356 0.91666667]\n",
      " [0.61111111 0.41666667 0.76271186 0.70833333]\n",
      " [0.94444444 0.75       0.96610169 0.875     ]\n",
      " [0.94444444 0.25       1.         0.91666667]\n",
      " [0.47222222 0.08333333 0.6779661  0.58333333]\n",
      " [0.72222222 0.5        0.79661017 0.91666667]\n",
      " [0.36111111 0.33333333 0.66101695 0.79166667]\n",
      " [0.94444444 0.33333333 0.96610169 0.79166667]\n",
      " [0.55555556 0.29166667 0.66101695 0.70833333]\n",
      " [0.66666667 0.54166667 0.79661017 0.83333333]\n",
      " [0.80555556 0.5        0.84745763 0.70833333]\n",
      " [0.52777778 0.33333333 0.6440678  0.70833333]\n",
      " [0.5        0.41666667 0.66101695 0.70833333]\n",
      " [0.58333333 0.33333333 0.77966102 0.83333333]\n",
      " [0.80555556 0.41666667 0.81355932 0.625     ]\n",
      " [0.86111111 0.33333333 0.86440678 0.75      ]\n",
      " [1.         0.75       0.91525424 0.79166667]\n",
      " [0.58333333 0.33333333 0.77966102 0.875     ]\n",
      " [0.55555556 0.33333333 0.69491525 0.58333333]\n",
      " [0.5        0.25       0.77966102 0.54166667]\n",
      " [0.94444444 0.41666667 0.86440678 0.91666667]\n",
      " [0.55555556 0.58333333 0.77966102 0.95833333]\n",
      " [0.58333333 0.45833333 0.76271186 0.70833333]\n",
      " [0.47222222 0.41666667 0.6440678  0.70833333]\n",
      " [0.72222222 0.45833333 0.74576271 0.83333333]\n",
      " [0.66666667 0.45833333 0.77966102 0.95833333]\n",
      " [0.72222222 0.45833333 0.69491525 0.91666667]\n",
      " [0.41666667 0.29166667 0.69491525 0.75      ]\n",
      " [0.69444444 0.5        0.83050847 0.91666667]\n",
      " [0.66666667 0.54166667 0.79661017 1.        ]\n",
      " [0.66666667 0.41666667 0.71186441 0.91666667]\n",
      " [0.55555556 0.20833333 0.6779661  0.75      ]\n",
      " [0.61111111 0.41666667 0.71186441 0.79166667]\n",
      " [0.52777778 0.58333333 0.74576271 0.91666667]\n",
      " [0.44444444 0.41666667 0.69491525 0.70833333]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 歸一化資料\n",
    "scaler_minmax = MinMaxScaler()\n",
    "data_minmax = scaler_minmax.fit_transform(data)\n",
    "\n",
    "# 輸出結果\n",
    "print(data_minmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3823389e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82530129 0.43441097 1.75940407 0.75969263]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 標準化資料\n",
    "scaler_standard = StandardScaler()\n",
    "data_standard = scaler_standard.fit_transform(data)\n",
    "\n",
    "# 輸出結果\n",
    "print(data_standard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5720d",
   "metadata": {},
   "source": [
    "## 練習\n",
    "- 判定一下我們的 mushroom 資料集，哪些資料適合標準化哪些資料、哪些資料不適合標準化、哪些不應該處理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb677f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3e953b3",
   "metadata": {},
   "source": [
    "## 練習\n",
    "- 將一個欄位標準化後存進原本的表格之中，並且列印出表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73819617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f27d065",
   "metadata": {},
   "source": [
    "## 練習\n",
    "- 練習看看，有標準化的資料跟沒有標準化的資料使用 Logestic Regression 在同樣的 10 次迭代 max_iter 時他們是否有差異。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c97be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "741273dd",
   "metadata": {},
   "source": [
    "## 回家作業\n",
    "- 自行練習將 mushroom 資料做前處理，包含異常值檢查過濾、缺失值處理、資料轉換，根據欄位的特性決定該欄位該做何種處理後，再去比較沒處理並且使用相同模型預測出來的結果。\n",
    "- 比較方式在將資料切成 train 與 test 兩份，最終觀察以 test 的 f1-score 來去做評斷。\n",
    "\n",
    "hint: 所以你會需要訓練兩個 Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a006782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
